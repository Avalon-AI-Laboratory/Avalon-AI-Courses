{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1: Neural Network from Scratch (NumPy)\n",
        "\n",
        "In this lab, we will build a 2-layer neural network from scratch using **only NumPy** to classify a non-linear dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 0: Setup and Data Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate a \"moons\" dataset\n",
        "X, Y = sklearn.datasets.make_moons(n_samples=200, noise=0.20)\n",
        "# Reshape Y to be a row vector\n",
        "Y = Y.reshape(1, Y.shape[0])\n",
        "\n",
        "# Visualize the data\n",
        "plt.scatter(X[:,0], X[:,1], c=Y[0], s=40, cmap=plt.cm.Spectral);\n",
        "plt.title(\"Our Moons Dataset\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"Y shape: {Y.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Define Layer Sizes and Initialize Parameters\n",
        "\n",
        "We initialize weights with small random numbers to break symmetry.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    np.random.seed(2)\n",
        "    \n",
        "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
        "    b1 = np.zeros((n_h, 1))\n",
        "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
        "    b2 = np.zeros((n_y, 1))\n",
        "    \n",
        "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
        "    return parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Define Activation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Forward Propagation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    \n",
        "    # Layer 1\n",
        "    Z1 = np.dot(W1, X.T) + b1\n",
        "    A1 = np.tanh(Z1)\n",
        "    \n",
        "    # Layer 2\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    \n",
        "    cache = {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
        "    return A2, cache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Backward Propagation\n",
        "\n",
        "Using the Chain Rule to calculate gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def backward_propagation(parameters, cache, X, Y):\n",
        "    m = X.shape[0]\n",
        "    \n",
        "    W1 = parameters[\"W1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    A1 = cache[\"A1\"]\n",
        "    A2 = cache[\"A2\"]\n",
        "\n",
        "    # Output Layer Gradients\n",
        "    dZ2 = A2 - Y\n",
        "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
        "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "    \n",
        "    # Hidden Layer Gradients (derivative of tanh is 1 - A^2)\n",
        "    dA1 = np.dot(W2.T, dZ2)\n",
        "    dZ1 = dA1 * (1 - np.power(A1, 2))\n",
        "    dW1 = (1 / m) * np.dot(dZ1, X)\n",
        "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "    \n",
        "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
        "    return grads\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Update Parameters & Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_parameters(parameters, grads, learning_rate=1.2):\n",
        "    parameters[\"W1\"] = parameters[\"W1\"] - learning_rate * grads[\"dW1\"]\n",
        "    parameters[\"b1\"] = parameters[\"b1\"] - learning_rate * grads[\"db1\"]\n",
        "    parameters[\"W2\"] = parameters[\"W2\"] - learning_rate * grads[\"dW2\"]\n",
        "    parameters[\"b2\"] = parameters[\"b2\"] - learning_rate * grads[\"db2\"]\n",
        "    return parameters\n",
        "\n",
        "def nn_model(X, Y, n_h, num_iterations=10000, print_cost=False):\n",
        "    np.random.seed(3)\n",
        "    n_x = X.shape[1]\n",
        "    n_y = Y.shape[0]\n",
        "    \n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    \n",
        "    for i in range(0, num_iterations):\n",
        "        A2, cache = forward_propagation(X, parameters)\n",
        "        \n",
        "        # Cost (Cross Entropy)\n",
        "        logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), (1 - Y))\n",
        "        cost = - (1 / n_x) * np.sum(logprobs) # Note: divisor depends on implementation, usually m\n",
        "        \n",
        "        grads = backward_propagation(parameters, cache, X, Y)\n",
        "        parameters = update_parameters(parameters, grads)\n",
        "        \n",
        "        if print_cost and i % 1000 == 0:\n",
        "            print (f\"Cost after iteration {i}: {cost}\")\n",
        "            \n",
        "    return parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters = nn_model(X, Y, n_h=4, num_iterations=10000, print_cost=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Decision Boundary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(parameters, X):\n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    return (A2 > 0.5)\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    h = 0.01\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
        "    plt.ylabel('x2')\n",
        "    plt.xlabel('x1')\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(lambda x: predict(parameters, x), X, Y[0])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}