{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Normalization Challenge**\n",
    "\n",
    "Okay! Since you've (hopefully,) by this point, gone thru _all_ of the materials on _Normalization_, we'll have a bit of a challenge thingy to assess your understanding and application.\n",
    "\n",
    "What you need to do, is change each of `my_normalization_func_*` to \"normalize\" the data on each challenge to allow for the binary classifier to decode correctly for the flag. To know whether you've fully succeeded, at the end, there's a checker for _all_ the flags on every challenge at once. If your code, when ran all the way from top to bottom, gets the output of \"success\" at the end, that means you've completed the challenge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**\n",
    "\n",
    "You can ignore this bit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import hashlib\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# --- Suppress Warnings ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "# --- Flag Utility (shared by all challenges) ---\n",
    "def binary_to_flag(bin_array):\n",
    "    \"\"\"Converts a numpy array of bits back to a string.\"\"\"\n",
    "    try:\n",
    "        bin_str = \"\".join(map(str, bin_array))\n",
    "        byte_chunks = [bin_str[i : i + 8] for i in range(0, len(bin_str), 8)]\n",
    "        chars = [chr(int(byte, 2)) for byte in byte_chunks]\n",
    "        return \"\".join(chars)\n",
    "    except Exception:\n",
    "        return \"failed :<\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Challenges**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  Challenge A ---\n",
      "\n",
      "Running Your Clean Model (Test 2)...\n",
      "Your Model Decoded Flag:   MC\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#  CHALLENGE A\n",
    "# ==========================================================\n",
    "print(\"---  Challenge A ---\")\n",
    "\n",
    "# --- 1. Challenge A Data ---\n",
    "\n",
    "train_texts_A = [\n",
    "    \"i love it\",\n",
    "    \"I LOVE IT!!\",\n",
    "    \"good\",\n",
    "    \"GOOD!\",\n",
    "    \"hate\",\n",
    "    \"HATE.\",\n",
    "    \"awful\",\n",
    "    \"AWFUL!!\",\n",
    "    \"great!\",\n",
    "    \"terrible :(\",\n",
    "]\n",
    "train_labels_A = [1, 1, 1, 1, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "test_texts_A = [\n",
    "    \"hate it\",\n",
    "    \"love\",\n",
    "    \"Good!\",\n",
    "    \"AWFUL\",\n",
    "    \"i love\",\n",
    "    \"I LOVE\",\n",
    "    \"good.\",\n",
    "    \"love it!!\",\n",
    "    \"HATE!!\",\n",
    "    \"i like it\",\n",
    "    \"great\",\n",
    "    \"terrible\",\n",
    "    \"GOOD!!\",\n",
    "    \"awful.\",\n",
    "    \"love\",\n",
    "    \"good\",\n",
    "]\n",
    "\n",
    "\n",
    "# --- 2. Student's Task ---\n",
    "def my_normalization_func_A(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- 3. Checker Cell (Your Model) ---\n",
    "print(\"\\nRunning Your Clean Model (Test 2)...\")\n",
    "try:\n",
    "    model_clean_A = make_pipeline(\n",
    "        CountVectorizer(\n",
    "            preprocessor=my_normalization_func_A,\n",
    "            tokenizer=lambda x: x.split(),\n",
    "        ),\n",
    "        LogisticRegression(max_iter=1000, random_state=42),  # DONT CHANGE THIS\n",
    "    )\n",
    "    model_clean_A.fit(train_texts_A, train_labels_A)\n",
    "    preds_clean_A = model_clean_A.predict(test_texts_A)\n",
    "\n",
    "    flag_piece_A = binary_to_flag(preds_clean_A)\n",
    "\n",
    "    print(f\"Your Model Decoded Flag:   {flag_piece_A}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n ERROR: Your function failed to run. {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---  Challenge B ---\n",
      "\n",
      "Running Your Model...\n",
      "Your Model Decoded Flag:   每茂\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#  CHALLENGE B: Stop-Word Removal\n",
    "# ==========================================================\n",
    "print(\"\\n---  Challenge B ---\")\n",
    "\n",
    "# --- 1. Challenge B Data ---\n",
    "\n",
    "train_texts_B = [\n",
    "    \"that code is.\",\n",
    "    \"Is The SERVER?\",\n",
    "    \"I HAS PYTHON.\",\n",
    "    \"The Tree has Been\",\n",
    "    \"Between Rivers, was Ours.\",\n",
    "    \"He had A *LEAF*.\",\n",
    "]\n",
    "train_labels_B = [1, 1, 1, 0, 0, 0]\n",
    "\n",
    "test_texts_B = [\n",
    "    \"that is a very, very, tree.\",\n",
    "    \"i AM python!!!\",\n",
    "    \"the server\",\n",
    "    \"what a code\",\n",
    "    \"It is a leaf.\",\n",
    "    \"*are* the rivers?\",\n",
    "    \"MY code... was.\",\n",
    "    \"a server, and you, and me\",\n",
    "    \"just, rivers\",\n",
    "    \"that Python *was*...\",\n",
    "    \"a SERVER is..?\",\n",
    "    \"He... had python\",\n",
    "    \"Such is, The Leaf.\",\n",
    "    \"Python is OURS!!\",\n",
    "    \"**SOME** of the code...\",\n",
    "    \"i AM server!\",\n",
    "]\n",
    "\n",
    "# --- 2. Student's Task ---\n",
    "stop_words_B = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def my_normalization_func_B(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- 3. Checker Cell (Your Model) ---\n",
    "print(\"\\nRunning Your Model...\")\n",
    "try:\n",
    "    model_clean_B = make_pipeline(\n",
    "        CountVectorizer(\n",
    "            preprocessor=my_normalization_func_B,\n",
    "            tokenizer=lambda x: x.split(),\n",
    "        ),\n",
    "        LogisticRegression(max_iter=1000, random_state=42),  # DONT CHANGE THIS\n",
    "    )\n",
    "\n",
    "    model_clean_B.fit(train_texts_B, train_labels_B)\n",
    "    preds_clean_B = model_clean_B.predict(test_texts_B)\n",
    "    flag_piece_B = binary_to_flag(preds_clean_B)\n",
    "\n",
    "    print(f\"Your Model Decoded Flag:   {flag_piece_B}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n ERROR: Your function failed to run. {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---  Challenge C ---\n",
      "\n",
      "Running Your Model...\n",
      "Your Model Decoded Flag:   没媒{m\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#  CHALLENGE C\n",
    "# ==========================================================\n",
    "print(\"\\n---  Challenge C ---\")\n",
    "\n",
    "# --- 1. Challenge C Data ---\n",
    "train_texts_C = [\"run\", \"walk\", \"comput\", \"run\", \"walk\", \"comput\"]\n",
    "train_labels_C = [1, 0, 1, 1, 0, 1]\n",
    "\n",
    "test_texts_C = [\n",
    "    \"walking\",\n",
    "    \"i am running\",\n",
    "    \"he runs\",\n",
    "    \"they run\",\n",
    "    \"walking\",\n",
    "    \"a walk\",\n",
    "    \"computers\",\n",
    "    \"i like running\",\n",
    "    \"he walked\",\n",
    "    \"a computer\",\n",
    "    \"runs\",\n",
    "    \"computers\",\n",
    "    \"walking slowly\",\n",
    "    \"i am computing\",\n",
    "    \"a long walk\",\n",
    "    \"they walked\",\n",
    "    \"a slow walk\",\n",
    "    \"walking\",\n",
    "    \"fast computer\",\n",
    "    \"running\",\n",
    "    \"walking\",\n",
    "    \"a walk\",\n",
    "    \"runs\",\n",
    "    \"running\",\n",
    "    \"a walk\",\n",
    "    \"computing\",\n",
    "    \"running\",\n",
    "    \"a walk\",\n",
    "    \"computers\",\n",
    "    \"running\",\n",
    "    \"a walk\",\n",
    "    \"he runs\",\n",
    "]\n",
    "\n",
    "# --- 2. Student's Task ---\n",
    "stop_words_C = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "def my_normalization_func_C(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "# --- 3. Checker Cell (Your Model) ---\n",
    "print(\"\\nRunning Your Model...\")\n",
    "try:\n",
    "    model_clean_C = make_pipeline(\n",
    "        CountVectorizer(\n",
    "            preprocessor=my_normalization_func_C,\n",
    "            tokenizer=lambda x: x.split(),\n",
    "        ),\n",
    "        LogisticRegression(max_iter=1000, random_state=42),  # DONT CHANGE THIS\n",
    "    )\n",
    "\n",
    "    model_clean_C.fit(train_texts_C, train_labels_C)\n",
    "    preds_clean_C = model_clean_C.predict(test_texts_C)\n",
    "    flag_piece_C = binary_to_flag(preds_clean_C)\n",
    "\n",
    "    print(f\"Your Model Decoded Flag:   {flag_piece_C}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n ERROR: Your function failed to run. {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  FLAG CHECK ---\n",
      "FLAG YOU GOT: avalon{MC_每茂_没媒{m}\n",
      "锔 hmm, not yet... try rechecking your answers! :< 锔\n"
     ]
    }
   ],
   "source": [
    "print(\"---  FLAG CHECK ---\")\n",
    "\n",
    "print(f\"FLAG YOU GOT: avalon{{{flag_piece_A}_{flag_piece_B}_{flag_piece_C}}}\")\n",
    "\n",
    "if (\n",
    "    hashlib.sha256(\n",
    "        f\"avalon{{{flag_piece_A}_{flag_piece_B}_{flag_piece_C}}}\".encode(\"utf8\")\n",
    "    ).hexdigest()\n",
    "    == \"fc3ee9a2b3e5f50a38fda5272540e61072e155c4141ecfc0afcd795257ad4133\"\n",
    "):\n",
    "    print(\" CONGRATS, YOU DID IT :3 \")\n",
    "else:\n",
    "    print(\"锔 hmm, not yet... try rechecking your answers! :< 锔\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
